{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1A) Implement a Naive Bayes classifier\n",
    "\n",
    "  - We use categorical attributes by discretizing each attribute into three equally-sized bins: low, medium, high.\n",
    "  - We need to apply smoothing to avoid zero probabilities.\n",
    "  - Additionally, we compute probabilities in the log space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import pprint\n",
    "import math\n",
    "\n",
    "ATTRS = [\"sepal_length\", \"sepal_width\", \"petal_length\", \"petal_width\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes classifier using categorical attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class NB(object):\n",
    "    def __init__(self):\n",
    "        self.model = None\n",
    "    \n",
    "    def train(self, attributes, labels):\n",
    "        self.model = {}\n",
    "        ccounter = Counter(labels)\n",
    "        numclasses = len(ccounter)\n",
    "        for l, freq in ccounter.items():\n",
    "            # class prior probabilities P(Y)\n",
    "            self.model[l] = {'P(Y)': freq / len(labels)}\n",
    "            # conditional probabilities P(X=x|Y=y)\n",
    "            for a in ATTRS:\n",
    "                for v in [\"low\", \"medium\", \"high\"]:\n",
    "                    # count how many times attribute `a` has value `v` when the target class is `l`\n",
    "                    cnt = sum(attributes[i][a] == v and labels[i] == l for i in range(len(attributes)))\n",
    "                    # store is as key \"a=v\"\n",
    "                    key = a + \"=\" + v\n",
    "                    # apply Laplace smoothing\n",
    "                    self.model[l][key] = (cnt + 1) / (freq + numclasses)\n",
    "                                \n",
    "        # pprint.pprint(self.model)\n",
    "    \n",
    "    def apply(self, attributes):\n",
    "        if not self.model:\n",
    "            raise Exception(\"Model has not been trained\")\n",
    "        # P(Y|X) \\propto P(Y) * P(X_1|Y) * ... * P(X_n|Y)\n",
    "        # in log space: \n",
    "        # log P(Y|X) \\propto log P(Y) + log P(X_1|Y) + ... + log P(X_n|Y)\n",
    "        maxp = float(\"-inf\") \n",
    "        maxl = None\n",
    "        for l, p in self.model.items():\n",
    "            prob = math.log(p['P(Y)'])  # log P(Y)\n",
    "            expl = \"P(\" + l + \")=\" + str(prob)  # explanation string (only for debugging)\n",
    "            for a in ATTRS:\n",
    "                key = a + '=' + attributes[a]\n",
    "                prob += math.log(p[key])  # + log P(X_i|Y)\n",
    "                expl += \" * P(\" + key + \"|\" + l +\")=\" + str(prob)\n",
    "            #print(expl)  # debug\n",
    "            if prob > maxp:\n",
    "                maxp = prob\n",
    "                maxl = l\n",
    "         \n",
    "        return maxl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data(filename):\n",
    "    train_x = []\n",
    "    train_y = []\n",
    "    test_x = []\n",
    "    test_y = []\n",
    "    with open(filename, 'rt') as csvfile:\n",
    "        csvreader = csv.reader(csvfile, delimiter=',')\n",
    "        i = 0\n",
    "        for row in csvreader:\n",
    "            if len(row) == 5:\n",
    "                i += 1\n",
    "                instance = {ATTRS[i]: float(row[i]) for i in range(4)}  # first four values are attributes\n",
    "                label = row[4]  # 5th value is the class label\n",
    "                if i % 3 == 0:  # test instance\n",
    "                    test_x.append(instance)\n",
    "                    test_y.append(label)\n",
    "                else:  # train instance\n",
    "                    train_x.append(instance)\n",
    "                    train_y.append(label)\n",
    "                    \n",
    "    return train_x, train_y, test_x, test_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def evaluate(predictions, true_labels):\n",
    "    correct = 0\n",
    "    incorrect = 0\n",
    "    for i in range(len(predictions)):\n",
    "        if predictions[i] == true_labels[i]:\n",
    "            correct += 1\n",
    "        else:\n",
    "            incorrect += 1\n",
    "\n",
    "    print(\"Accuracy:   \", correct / len(predictions))\n",
    "    print(\"Error rate: \", incorrect / len(predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discretization\n",
    "\n",
    "We need to replace numerical values with labels 'low', 'medium', 'high' such that 1/3 of the values are assigned 'low', 1/3 of the values are assigned 'medium', and 1/3 of the values are assigned 'high'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def discretize(attributes):\n",
    "    attrs2 = [{} for _ in range(len(attributes))]  # initialize list of empty dicts\n",
    "    for a in ATTRS:\n",
    "        # find thresholds\n",
    "        values = np.array([x[a] for x in attributes])\n",
    "        t1 = np.percentile(values, 100/3)  # 33.3th percentile\n",
    "        t2 = np.percentile(values, 2*100/3)  # 66.6th percentile\n",
    "        for i in range(len(attributes)):\n",
    "            val = attributes[i][a]\n",
    "            if val <= t1:\n",
    "                val2 = \"low\" \n",
    "            elif val > t2:\n",
    "                val2 = \"high\"\n",
    "            else:\n",
    "                val2 = \"medium\"\n",
    "            attrs2[i][a] = val2\n",
    "     \n",
    "    return attrs2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main logic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_x, train_y, test_x, test_y = load_data(\"../data/iris.data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discretize attribute values\n",
    "Importantly, we do it on the entire data set (training and testing), to ensure that values are assigned to the same bins in the train and in the test part. We then split back the data into train and test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x2 = discretize(train_x + test_x)\n",
    "train_x2 = x2[:len(train_x)]\n",
    "test_x2 = x2[-len(test_x):]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nb = NB()\n",
    "nb.train(train_x2, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions = []\n",
    "for instance in test_x2:\n",
    "    label = nb.apply(instance)\n",
    "    predictions.append(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:    0.94\n",
      "Error rate:  0.06\n"
     ]
    }
   ],
   "source": [
    "evaluate(predictions, test_y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
